{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/09 23:17:00 WARN Utils: Your hostname, Ashleys-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.149 instead (on interface en0)\n",
      "23/04/09 23:17:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/09 23:17:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/09 23:17:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark import sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import avg\n",
    "import re\n",
    "\n",
    "sc = SparkContext()\n",
    "sqlContext = sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Data from file\n",
    "dataRDD = sc.textFile(\"Amazon_Comments.csv\").map(lambda x:x.split(\"^\"))\n",
    "\n",
    "#Find length of review\n",
    "dataRDDnew = dataRDD.map(lambda x:(x[0],x[1],x[2],x[3],x[4],x[5],x[6],len(re.sub('W+',' ',x[5]).strip().split(' '))))\n",
    "\n",
    "#Loadning Data into SparkDataFrame\n",
    "dataDF = dataRDDnew.toDF([\"ProductID\",\"ReviewID\", \"ReviewTitle\",\"ReviewTime\",\"Verified\",\"Review\",\"Rating\",\"Length\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#Using Dataframe  SQL to find average length by Rating\n",
    "#Your Code Here\n",
    "# Loadning Data into SparkDataFrame\n",
    "dataDF.createOrReplaceTempView(\"reviews\")\n",
    "results = sqlContext.sql(\"SELECT Rating, AVG(Length) as AvgLength FROM reviews GROUP BY Rating\")\n",
    "\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = sorted(results.collect())\n",
    "\n",
    "#Print Output\n",
    "for i in answer:\n",
    "\tprint(str(i[0])+ \" Star Rating: Average Length of Comments \"+ str(i[1]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
